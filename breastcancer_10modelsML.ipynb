{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_CK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eLfYIAGvNtsF"
      },
      "outputs": [],
      "source": [
        "#link data from kaggle \n",
        "#https://www.kaggle.com/uciml/breast-cancer-wisconsin-data "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import cycle, islice\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import parallel_coordinates\n",
        "import io\n",
        "from google.colab import files\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1sZJcZ7-N3dV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['data.csv']))"
      ],
      "metadata": {
        "id": "_r3p8f5D2hzV",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "16e62172-f4bc-4ef1-8137-69dc48df1210"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-753c80c8-9bc7-473f-8b22-c4aa78a90f74\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-753c80c8-9bc7-473f-8b22-c4aa78a90f74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "oCfYn-X7N97N",
        "outputId": "55d3bc9b-a2d4-4271-9bdd-19dc89d7501d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff86c073-4f07-4353-9fdd-5ae3a5691964\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff86c073-4f07-4353-9fdd-5ae3a5691964')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff86c073-4f07-4353-9fdd-5ae3a5691964 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff86c073-4f07-4353-9fdd-5ae3a5691964');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn đoán các giá trị trong cột diagnosis -> hình dung số lượng giá trị của các cột 'diagnosis' để dễ hiểu hơn\n",
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVOwDRHDN_fc",
        "outputId": "9c1d6ade-d0b3-4e38-ba86-5236a1a69b2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tìm xem trong data các cột có giá trị null\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYW3yinkOZ2A",
        "outputId": "586e8ab0-868c-4c42-dd66-8d51e540a360"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           0\n",
              "diagnosis                    0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 32','id'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ylNkQC3mWiB9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trong dataset có 2 biến : biến độc lập và phụ thuộc. Nên chúng ta chia ra làm 2\n",
        "# Biến độc lập\n",
        "x = df.drop('diagnosis',axis=1)\n",
        "#Biến phụ thuộc\n",
        "y = df.diagnosis"
      ],
      "metadata": {
        "id": "UHKPt9FkOsPL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do y có chứa data phân loại nên sẽ convert data sang binary\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(y)"
      ],
      "metadata": {
        "id": "iktbC1O7PFYM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chuẩn hoá dữ liệu\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3,random_state=40)"
      ],
      "metadata": {
        "id": "p0R1KgKsPbO3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling dữ liệu\n",
        "#importing StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "xtrain = sc.fit_transform(xtrain)\n",
        "xtest = sc.transform(xtest)"
      ],
      "metadata": {
        "id": "x4MZBBkdPg86"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANN**"
      ],
      "metadata": {
        "id": "yd7zb2lTPw-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import các module từ keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "1E5aYbdKP0cb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tạo model\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "Ut9gEhIeP6Rf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thêm các input layer,first hidden layer\n",
        "classifier.add(Dense(units=16, activation='relu', input_dim=30,kernel_initializer=\"uniform\"))\n",
        "# add dropout -> ngăn overfitting\n",
        "classifier.add(Dropout(rate=0.1))"
      ],
      "metadata": {
        "id": "_hu2BmvUTIvr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
      ],
      "metadata": {
        "id": "2H47VCTrVw9W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoOjq42XP-wj",
        "outputId": "b2439748-35ae-4f35-e82e-c01ff9f49179"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                496       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pYnCtvrPQBqM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(xtrain, ytrain, batch_size=100, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0WgrNBPQiWV",
        "outputId": "e2e69f54-dcd1-4318-8e71-b11c703e690e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.6106\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.8819\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.8920\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.9020\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.9095\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.9070\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.9070\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.9146\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.9146\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.9196\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.9146\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.9146\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.9146\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.9146\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.9196\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.9221\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.9246\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.9271\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.9296\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.9296\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.9322\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.9347\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.9347\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.9472\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.9422\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9523\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2549 - accuracy: 0.9472\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2439 - accuracy: 0.9497\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2350 - accuracy: 0.9548\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9573\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9497\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.9573\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2016 - accuracy: 0.9548\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9548\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9548\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9548\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9623\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9598\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9623\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9673\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9648\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9673\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9648\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9724\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9698\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9724\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9698\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9698\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9749\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9749\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9774\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1242 - accuracy: 0.9774\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9749\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9749\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9774\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9774\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9774\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9774\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9774\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9749\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9824\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9774\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9749\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9799\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9799\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9774\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9799\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9799\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9799\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9799\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9799\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9774\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9824\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9824\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9774\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9799\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9849\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9849\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9849\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9849\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9824\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9824\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9799\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9824\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9824\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9824\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9824\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9824\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9824\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9799\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9824\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9824\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9824\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9799\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9824\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9799\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9849\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9824\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9824\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9824\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9824\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9824\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9824\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9824\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9824\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9824\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9824\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9824\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9824\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9824\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.9824\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9824\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9824\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9824\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9824\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9824\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9824\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9824\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9824\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9799\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9824\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9824\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9824\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9799\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9824\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9824\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9824\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9824\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9824\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9849\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9824\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9824\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9824\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9824\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0623 - accuracy: 0.9824\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9824\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9824\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9824\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9824\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9824\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9824\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9824\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9824\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9824\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9824\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9824\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9824\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9824\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9824\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd1c6d94490>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering, Kmeans, Kmedoids"
      ],
      "metadata": {
        "id": "u5VOx5AEZtWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=12)\n",
        "model = kmeans.fit(xtrain)\n",
        "print(\"model\\n\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHZfFAnoZsK8",
        "outputId": "a14bdb7e-0b40-4f82-b69f-5bfaa1270934"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            " KMeans(n_clusters=12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "centers = model.cluster_centers_\n",
        "centers"
      ],
      "metadata": {
        "id": "jMC0p38oZ0ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad480993-1ade-4d33-8ee3-e5c2c0a765ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.10618966e-02, -4.51840985e-02, -2.27457965e-02,\n",
              "        -1.45153483e-01,  3.48287262e-01,  3.51269140e-01,\n",
              "         4.34880984e-02,  1.02174526e-01,  1.19328209e-01,\n",
              "         1.96001446e-01, -3.80450831e-01, -4.75522973e-01,\n",
              "        -3.36042240e-01, -3.19790493e-01, -3.96804899e-01,\n",
              "         5.60995953e-02, -4.97914921e-02,  5.79771668e-03,\n",
              "        -4.19628117e-01, -8.79501867e-02, -4.74604279e-02,\n",
              "         1.75183913e-02, -1.39342888e-02, -1.58882393e-01,\n",
              "         4.17640257e-01,  5.39554229e-01,  3.06360656e-01,\n",
              "         3.83767435e-01,  2.44300605e-01,  4.90056753e-01],\n",
              "       [-3.21565672e-01,  7.51625661e-01, -3.72687999e-01,\n",
              "        -3.50727646e-01, -8.77389363e-01, -9.41792853e-01,\n",
              "        -7.76855091e-01, -7.23278300e-01, -6.85046882e-01,\n",
              "        -7.49841580e-01, -2.40785577e-01,  5.61976680e-01,\n",
              "        -3.07119105e-01, -2.83647153e-01, -4.37852560e-01,\n",
              "        -7.64675092e-01, -5.75586514e-01, -6.33294579e-01,\n",
              "        -2.62059158e-01, -5.79403359e-01, -3.64077227e-01,\n",
              "         6.61921510e-01, -4.23880865e-01, -3.82838742e-01,\n",
              "        -9.62671560e-01, -8.98759609e-01, -8.15947344e-01,\n",
              "        -8.18792836e-01, -7.13787840e-01, -8.84180684e-01],\n",
              "       [ 1.80752283e+00,  6.04190253e-01,  2.08452756e+00,\n",
              "         1.88401196e+00,  2.31326018e+00,  3.89215160e+00,\n",
              "         3.67798064e+00,  3.09919049e+00,  2.99940684e+00,\n",
              "         1.83002907e+00,  3.12358457e+00,  1.97056482e+00,\n",
              "         3.58430155e+00,  2.87876857e+00,  2.09063907e+00,\n",
              "         3.11827002e+00,  2.28087047e+00,  2.14830838e+00,\n",
              "         2.85581369e+00,  1.19271242e+00,  1.64457723e+00,\n",
              "         5.44121504e-01,  1.99195023e+00,  1.60972667e+00,\n",
              "         1.41392428e+00,  2.09477375e+00,  2.18022794e+00,\n",
              "         2.11440656e+00,  1.78915656e+00,  6.65266013e-01],\n",
              "       [ 1.21054151e+00,  5.53496172e-01,  1.14880678e+00,\n",
              "         1.16458612e+00, -2.76166303e-01, -1.35309564e-03,\n",
              "         2.87744310e-01,  6.16478093e-01, -2.48959654e-01,\n",
              "        -1.04063588e+00,  4.14844720e-01, -3.77183198e-01,\n",
              "         3.34058957e-01,  4.61114559e-01, -4.16872840e-01,\n",
              "        -2.55153563e-01, -1.01147069e-01,  1.20906469e-01,\n",
              "        -4.56904608e-01, -4.80621231e-01,  1.20540042e+00,\n",
              "         5.68121535e-01,  1.12425159e+00,  1.12087349e+00,\n",
              "         9.14724023e-02,  1.45943108e-01,  3.66546801e-01,\n",
              "         7.76482734e-01,  1.29662497e-01, -4.40047254e-01],\n",
              "       [-1.11346956e+00, -3.32163902e-01, -1.10492401e+00,\n",
              "        -9.56888039e-01,  2.22463310e-01, -5.89292849e-01,\n",
              "        -7.44555664e-01, -7.92502259e-01,  2.53370234e-01,\n",
              "         5.12940260e-01, -3.68860259e-01,  6.30092756e-01,\n",
              "        -3.87457565e-01, -4.78398740e-01,  1.08322328e+00,\n",
              "        -3.69157632e-01, -4.24785855e-01, -4.64288553e-01,\n",
              "         7.13355779e-01,  4.93535292e-02, -1.04411199e+00,\n",
              "        -3.81583726e-01, -1.04252995e+00, -8.67619084e-01,\n",
              "         1.36522492e-01, -7.62119610e-01, -8.55027792e-01,\n",
              "        -9.83617691e-01, -1.44224511e-01, -2.01521871e-01],\n",
              "       [-3.59559479e-01, -8.28287904e-01, -3.95692585e-01,\n",
              "        -4.02371564e-01, -6.06026971e-01, -7.38276511e-01,\n",
              "        -7.10889433e-01, -7.00397722e-01, -5.96795514e-01,\n",
              "        -5.16360021e-01, -6.31982604e-01, -7.26699609e-01,\n",
              "        -6.46560287e-01, -4.96060779e-01, -5.25805713e-01,\n",
              "        -6.40409248e-01, -4.86662548e-01, -6.83910820e-01,\n",
              "        -4.05571728e-01, -5.65164324e-01, -4.33198149e-01,\n",
              "        -8.00815429e-01, -4.67459511e-01, -4.55196480e-01,\n",
              "        -5.71250260e-01, -6.17814133e-01, -6.37480489e-01,\n",
              "        -6.52050873e-01, -3.47312703e-01, -5.82554885e-01],\n",
              "       [ 2.18308402e+00,  7.78760080e-01,  2.21291966e+00,\n",
              "         2.40958439e+00,  5.85241441e-01,  1.42781102e+00,\n",
              "         1.83144534e+00,  2.12132749e+00,  5.82287648e-01,\n",
              "        -1.07562695e-01,  1.98578095e+00, -1.94987031e-01,\n",
              "         2.01650431e+00,  2.09434405e+00, -4.11289579e-01,\n",
              "         5.61088194e-01,  5.35630771e-01,  7.25908335e-01,\n",
              "        -6.96630260e-02,  1.27490849e-01,  2.35636657e+00,\n",
              "         6.71463410e-01,  2.37874071e+00,  2.59268459e+00,\n",
              "         3.92478212e-01,  1.19376678e+00,  1.38893387e+00,\n",
              "         1.73749885e+00,  6.62131299e-01,  4.15686211e-01],\n",
              "       [-1.10153854e+00, -3.54463656e-02, -1.01818305e+00,\n",
              "        -9.28988683e-01,  2.81294853e-01,  1.10560670e+00,\n",
              "         1.80368146e+00,  3.94735897e-02,  1.32734796e+00,\n",
              "         2.90615253e+00, -1.59965218e-01,  1.31503338e+00,\n",
              "        -2.08958558e-01, -3.77424537e-01,  1.14557989e+00,\n",
              "         3.76916189e+00,  5.03345105e+00,  2.64387959e+00,\n",
              "         1.63366754e+00,  4.71447793e+00, -1.01766469e+00,\n",
              "         7.30587741e-02, -9.67918908e-01, -8.35550450e-01,\n",
              "         3.29017436e-01,  1.36080563e+00,  2.19711344e+00,\n",
              "         3.51257026e-01,  9.78332163e-01,  2.70231763e+00],\n",
              "       [ 4.43684130e-02,  3.27542930e-01,  1.49846205e-01,\n",
              "        -3.84697154e-02,  1.40113472e+00,  1.59567121e+00,\n",
              "         1.15283341e+00,  9.56142674e-01,  1.37002083e+00,\n",
              "         1.46219758e+00,  1.20616612e-01, -6.28004202e-02,\n",
              "         1.90253620e-01, -9.62120261e-03,  3.61006679e-01,\n",
              "         8.68395180e-01,  5.08717112e-01,  7.29482862e-01,\n",
              "         4.15948060e-01,  7.99955743e-01,  1.77808965e-01,\n",
              "         5.61015313e-01,  3.02229627e-01,  6.46138250e-02,\n",
              "         1.55383529e+00,  1.61154358e+00,  1.35701253e+00,\n",
              "         1.19272105e+00,  1.39828215e+00,  1.86294753e+00],\n",
              "       [ 3.73445213e+00,  1.70036295e+00,  3.87388322e+00,\n",
              "         5.24072035e+00,  8.40017440e-01,  1.83097144e+00,\n",
              "         3.39206008e+00,  3.06071155e+00,  8.75246208e-01,\n",
              "        -9.40964746e-01,  8.04210443e+00,  1.87041180e-01,\n",
              "         8.33003220e+00,  1.16360289e+01,  2.13131369e-01,\n",
              "         1.67676450e+00,  1.49729253e+00,  2.34479219e+00,\n",
              "        -4.40685296e-01,  3.18187229e-01,  4.02053315e+00,\n",
              "         9.70013835e-01,  4.22752545e+00,  5.82825226e+00,\n",
              "         1.47566956e-01,  1.15746636e+00,  1.94778280e+00,\n",
              "         2.25792561e+00, -4.44999306e-01, -5.72459041e-01],\n",
              "       [-6.65424317e-01, -4.32482871e-01, -6.20175179e-01,\n",
              "        -6.46995281e-01, -2.16949230e-01,  2.43074320e-01,\n",
              "         5.64178334e-02, -3.30093524e-01, -4.44316821e-01,\n",
              "         8.69755073e-01, -3.50797869e-01,  3.92457808e-01,\n",
              "        -1.20518634e-01, -4.10874115e-01,  6.89018297e-01,\n",
              "         1.30566501e+00,  9.12601597e-01,  8.78798686e-01,\n",
              "         6.63752128e-02,  1.14881445e+00, -7.04460721e-01,\n",
              "        -4.85224909e-01, -6.13944227e-01, -6.54606588e-01,\n",
              "        -3.75702824e-01,  3.22197697e-01,  2.34572296e-01,\n",
              "        -2.22688515e-01, -6.91604032e-01,  6.01079670e-01],\n",
              "       [ 1.23982005e+00,  7.11876595e-01,  1.24083437e+00,\n",
              "         1.19761079e+00,  5.31006350e-01,  7.50515228e-01,\n",
              "         1.02358488e+00,  1.25100433e+00,  4.44075089e-01,\n",
              "        -1.65704663e-01,  1.29283398e+00,  5.64045154e-01,\n",
              "         1.18011228e+00,  1.10518201e+00,  1.55315917e-01,\n",
              "         4.82548245e-01,  3.94665871e-01,  8.80856296e-01,\n",
              "         3.62862517e-01,  2.78232716e-01,  1.22151543e+00,\n",
              "         6.48350095e-01,  1.19037535e+00,  1.12981076e+00,\n",
              "         4.27587816e-01,  4.70760272e-01,  6.77098663e-01,\n",
              "         9.97547142e-01,  2.80152739e-01,  7.86995086e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-extra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH-aWfQjZ3CB",
        "outputId": "68789e4c-cd37-4cf0-8124-eff716000dc2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn-extra\n",
            "  Downloading scikit_learn_extra-0.2.0-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 378 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 430 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 593 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 665 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 778 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 890 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.1.0)\n",
            "Installing collected packages: scikit-learn-extra\n",
            "Successfully installed scikit-learn-extra-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_extra.cluster import KMedoids\n",
        "kmedoids = KMedoids(n_clusters=12)\n",
        "kmedoids.fit(xtrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxvDYIVLZ4xB",
        "outputId": "5239fa95-acf8-499c-bbba-2eaf3acc71ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMedoids(n_clusters=12)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "centroid = kmeans.cluster_centers_\n",
        "labels = kmeans.labels_\n",
        "\n",
        "print(centroid)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "kFUF3x_vZ8EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ceac67d-4d6a-4b4d-ff09-f8e4c755a99e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.10618966e-02 -4.51840985e-02 -2.27457965e-02 -1.45153483e-01\n",
            "   3.48287262e-01  3.51269140e-01  4.34880984e-02  1.02174526e-01\n",
            "   1.19328209e-01  1.96001446e-01 -3.80450831e-01 -4.75522973e-01\n",
            "  -3.36042240e-01 -3.19790493e-01 -3.96804899e-01  5.60995953e-02\n",
            "  -4.97914921e-02  5.79771668e-03 -4.19628117e-01 -8.79501867e-02\n",
            "  -4.74604279e-02  1.75183913e-02 -1.39342888e-02 -1.58882393e-01\n",
            "   4.17640257e-01  5.39554229e-01  3.06360656e-01  3.83767435e-01\n",
            "   2.44300605e-01  4.90056753e-01]\n",
            " [-3.21565672e-01  7.51625661e-01 -3.72687999e-01 -3.50727646e-01\n",
            "  -8.77389363e-01 -9.41792853e-01 -7.76855091e-01 -7.23278300e-01\n",
            "  -6.85046882e-01 -7.49841580e-01 -2.40785577e-01  5.61976680e-01\n",
            "  -3.07119105e-01 -2.83647153e-01 -4.37852560e-01 -7.64675092e-01\n",
            "  -5.75586514e-01 -6.33294579e-01 -2.62059158e-01 -5.79403359e-01\n",
            "  -3.64077227e-01  6.61921510e-01 -4.23880865e-01 -3.82838742e-01\n",
            "  -9.62671560e-01 -8.98759609e-01 -8.15947344e-01 -8.18792836e-01\n",
            "  -7.13787840e-01 -8.84180684e-01]\n",
            " [ 1.80752283e+00  6.04190253e-01  2.08452756e+00  1.88401196e+00\n",
            "   2.31326018e+00  3.89215160e+00  3.67798064e+00  3.09919049e+00\n",
            "   2.99940684e+00  1.83002907e+00  3.12358457e+00  1.97056482e+00\n",
            "   3.58430155e+00  2.87876857e+00  2.09063907e+00  3.11827002e+00\n",
            "   2.28087047e+00  2.14830838e+00  2.85581369e+00  1.19271242e+00\n",
            "   1.64457723e+00  5.44121504e-01  1.99195023e+00  1.60972667e+00\n",
            "   1.41392428e+00  2.09477375e+00  2.18022794e+00  2.11440656e+00\n",
            "   1.78915656e+00  6.65266013e-01]\n",
            " [ 1.21054151e+00  5.53496172e-01  1.14880678e+00  1.16458612e+00\n",
            "  -2.76166303e-01 -1.35309564e-03  2.87744310e-01  6.16478093e-01\n",
            "  -2.48959654e-01 -1.04063588e+00  4.14844720e-01 -3.77183198e-01\n",
            "   3.34058957e-01  4.61114559e-01 -4.16872840e-01 -2.55153563e-01\n",
            "  -1.01147069e-01  1.20906469e-01 -4.56904608e-01 -4.80621231e-01\n",
            "   1.20540042e+00  5.68121535e-01  1.12425159e+00  1.12087349e+00\n",
            "   9.14724023e-02  1.45943108e-01  3.66546801e-01  7.76482734e-01\n",
            "   1.29662497e-01 -4.40047254e-01]\n",
            " [-1.11346956e+00 -3.32163902e-01 -1.10492401e+00 -9.56888039e-01\n",
            "   2.22463310e-01 -5.89292849e-01 -7.44555664e-01 -7.92502259e-01\n",
            "   2.53370234e-01  5.12940260e-01 -3.68860259e-01  6.30092756e-01\n",
            "  -3.87457565e-01 -4.78398740e-01  1.08322328e+00 -3.69157632e-01\n",
            "  -4.24785855e-01 -4.64288553e-01  7.13355779e-01  4.93535292e-02\n",
            "  -1.04411199e+00 -3.81583726e-01 -1.04252995e+00 -8.67619084e-01\n",
            "   1.36522492e-01 -7.62119610e-01 -8.55027792e-01 -9.83617691e-01\n",
            "  -1.44224511e-01 -2.01521871e-01]\n",
            " [-3.59559479e-01 -8.28287904e-01 -3.95692585e-01 -4.02371564e-01\n",
            "  -6.06026971e-01 -7.38276511e-01 -7.10889433e-01 -7.00397722e-01\n",
            "  -5.96795514e-01 -5.16360021e-01 -6.31982604e-01 -7.26699609e-01\n",
            "  -6.46560287e-01 -4.96060779e-01 -5.25805713e-01 -6.40409248e-01\n",
            "  -4.86662548e-01 -6.83910820e-01 -4.05571728e-01 -5.65164324e-01\n",
            "  -4.33198149e-01 -8.00815429e-01 -4.67459511e-01 -4.55196480e-01\n",
            "  -5.71250260e-01 -6.17814133e-01 -6.37480489e-01 -6.52050873e-01\n",
            "  -3.47312703e-01 -5.82554885e-01]\n",
            " [ 2.18308402e+00  7.78760080e-01  2.21291966e+00  2.40958439e+00\n",
            "   5.85241441e-01  1.42781102e+00  1.83144534e+00  2.12132749e+00\n",
            "   5.82287648e-01 -1.07562695e-01  1.98578095e+00 -1.94987031e-01\n",
            "   2.01650431e+00  2.09434405e+00 -4.11289579e-01  5.61088194e-01\n",
            "   5.35630771e-01  7.25908335e-01 -6.96630260e-02  1.27490849e-01\n",
            "   2.35636657e+00  6.71463410e-01  2.37874071e+00  2.59268459e+00\n",
            "   3.92478212e-01  1.19376678e+00  1.38893387e+00  1.73749885e+00\n",
            "   6.62131299e-01  4.15686211e-01]\n",
            " [-1.10153854e+00 -3.54463656e-02 -1.01818305e+00 -9.28988683e-01\n",
            "   2.81294853e-01  1.10560670e+00  1.80368146e+00  3.94735897e-02\n",
            "   1.32734796e+00  2.90615253e+00 -1.59965218e-01  1.31503338e+00\n",
            "  -2.08958558e-01 -3.77424537e-01  1.14557989e+00  3.76916189e+00\n",
            "   5.03345105e+00  2.64387959e+00  1.63366754e+00  4.71447793e+00\n",
            "  -1.01766469e+00  7.30587741e-02 -9.67918908e-01 -8.35550450e-01\n",
            "   3.29017436e-01  1.36080563e+00  2.19711344e+00  3.51257026e-01\n",
            "   9.78332163e-01  2.70231763e+00]\n",
            " [ 4.43684130e-02  3.27542930e-01  1.49846205e-01 -3.84697154e-02\n",
            "   1.40113472e+00  1.59567121e+00  1.15283341e+00  9.56142674e-01\n",
            "   1.37002083e+00  1.46219758e+00  1.20616612e-01 -6.28004202e-02\n",
            "   1.90253620e-01 -9.62120261e-03  3.61006679e-01  8.68395180e-01\n",
            "   5.08717112e-01  7.29482862e-01  4.15948060e-01  7.99955743e-01\n",
            "   1.77808965e-01  5.61015313e-01  3.02229627e-01  6.46138250e-02\n",
            "   1.55383529e+00  1.61154358e+00  1.35701253e+00  1.19272105e+00\n",
            "   1.39828215e+00  1.86294753e+00]\n",
            " [ 3.73445213e+00  1.70036295e+00  3.87388322e+00  5.24072035e+00\n",
            "   8.40017440e-01  1.83097144e+00  3.39206008e+00  3.06071155e+00\n",
            "   8.75246208e-01 -9.40964746e-01  8.04210443e+00  1.87041180e-01\n",
            "   8.33003220e+00  1.16360289e+01  2.13131369e-01  1.67676450e+00\n",
            "   1.49729253e+00  2.34479219e+00 -4.40685296e-01  3.18187229e-01\n",
            "   4.02053315e+00  9.70013835e-01  4.22752545e+00  5.82825226e+00\n",
            "   1.47566956e-01  1.15746636e+00  1.94778280e+00  2.25792561e+00\n",
            "  -4.44999306e-01 -5.72459041e-01]\n",
            " [-6.65424317e-01 -4.32482871e-01 -6.20175179e-01 -6.46995281e-01\n",
            "  -2.16949230e-01  2.43074320e-01  5.64178334e-02 -3.30093524e-01\n",
            "  -4.44316821e-01  8.69755073e-01 -3.50797869e-01  3.92457808e-01\n",
            "  -1.20518634e-01 -4.10874115e-01  6.89018297e-01  1.30566501e+00\n",
            "   9.12601597e-01  8.78798686e-01  6.63752128e-02  1.14881445e+00\n",
            "  -7.04460721e-01 -4.85224909e-01 -6.13944227e-01 -6.54606588e-01\n",
            "  -3.75702824e-01  3.22197697e-01  2.34572296e-01 -2.22688515e-01\n",
            "  -6.91604032e-01  6.01079670e-01]\n",
            " [ 1.23982005e+00  7.11876595e-01  1.24083437e+00  1.19761079e+00\n",
            "   5.31006350e-01  7.50515228e-01  1.02358488e+00  1.25100433e+00\n",
            "   4.44075089e-01 -1.65704663e-01  1.29283398e+00  5.64045154e-01\n",
            "   1.18011228e+00  1.10518201e+00  1.55315917e-01  4.82548245e-01\n",
            "   3.94665871e-01  8.80856296e-01  3.62862517e-01  2.78232716e-01\n",
            "   1.22151543e+00  6.48350095e-01  1.19037535e+00  1.12981076e+00\n",
            "   4.27587816e-01  4.70760272e-01  6.77098663e-01  9.97547142e-01\n",
            "   2.80152739e-01  7.86995086e-02]]\n",
            "[ 8  4  8  5  8  4  0  5  4  4  1  5  0  4  1  1 11  0  1  5  5  0  8  1\n",
            " 11  5  1  3  4  6 11  4  5 10  8  4  3 11  0 11  4  7  0  8  3  1  0 11\n",
            "  5  0 11  3 11  4  0  1  0  5 11  5  1 11  5  5  3  1  3  0  1  4  0  4\n",
            " 11  4  1  5  5  4  3  3  0  1 10  1  5  0  4  5  5  8  4  5 11 10 11  5\n",
            " 10  1  5  6 11  3  1  0  1  5 11  5  4  4  5  4  0  1 10  5  4  5  5  5\n",
            " 10  4  0  5 10  5  6  5  0  3 11  0  1  6  5  7 10  3 11  5  1  8  4  4\n",
            " 11 10  1  5  3  4  5  6  4  3  5  9  0  1  6  4  5  6  5  4  0  4  5  5\n",
            "  4 10  8  7  5 10  0  5  1 11  1  3  4  1  7 11 10  0  8  4  5  5 11  1\n",
            " 10  0 10  3  2 10  3  1  4  3 11  1  5  3  5  0  1  1  0 11  6  8  6  5\n",
            "  0 11  0  1  6  0  4  3 11  3  1  2  6  0 10  5  0  4  0  5  4  3 11  1\n",
            "  1  0  6  3  4  4  5  1  5  5  5 11 11  0  5 11  3  5  7  5  0  5  5  1\n",
            "  1  5 10  8  0 10  0  3 10  6  4 10  0  5  6  3  8  3  5  5  5  5  0  7\n",
            "  1  3  8  1  8  8  4  4  4  1  5  5  5  3  4  8  5 10  4 10  5  8  5  4\n",
            "  4  3 11  0  4  5  5  1  4  5  2  0  5  1  5  6  4 11  4  5  0  3  0  5\n",
            "  0  5  3  6  3 10  8  4  8  0  4  1  5  8 11  5  5 10  5 11  0  5  8  5\n",
            "  0  4  4  2  1  5  8 11  8  6  4  1  3  4 11  1  8  5  0  8  0  5  3  5\n",
            "  8 11  0  0  4  4  0  5  5 10  1  8  3  5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\n"
      ],
      "metadata": {
        "id": "E6HuwnyEYUr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf1 = svm.SVC(kernel='linear',C=1,gamma='auto') # Linear Kernel\n",
        "clf1.fit(xtrain, ytrain)\n",
        "\n",
        "y_pred_1= clf1.predict(xtest)"
      ],
      "metadata": {
        "id": "1uNCr5nDXYcd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf2 = svm.SVC(kernel='linear',C=2,gamma='auto') # Linear Kernel\n",
        "clf2.fit(xtrain, ytrain)\n",
        "\n",
        "y_pred_2= clf2.predict(xtest)"
      ],
      "metadata": {
        "id": "qGIlRnWjYvK6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf3 = svm.SVC(kernel='linear',C=3,gamma='auto') # Linear Kernel\n",
        "clf3.fit(xtrain, ytrain)\n",
        "\n",
        "y_pred_3= clf3.predict(xtest)"
      ],
      "metadata": {
        "id": "BYshVmVuZDrZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest,y_pred_1)) # C= 1 \n",
        "print(classification_report(ytest,y_pred_2)) # C= 2 \n",
        "print(classification_report(ytest,y_pred_3)) # C= 3 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI29zwPWZItp",
        "outputId": "7d31a402-d980-41a1-d84a-abc9b8dcaca1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       115\n",
            "           1       0.96      0.96      0.96        56\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98       115\n",
            "           1       0.95      0.96      0.96        56\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.96      0.97      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       115\n",
            "           1       0.96      0.96      0.96        56\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "svm = svm.SVC()\n",
        "scores = cross_val_score(svm, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrB6JTHGcSuq",
        "outputId": "092c5cb6-bd9a-4922-9d60-176dd840b980"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR"
      ],
      "metadata": {
        "id": "r88zZ4X8beRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Tạo model:\n",
        "lr = LogisticRegression()\n",
        "\n",
        "scores = cross_val_score(lr, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcqsaEmCbKFF",
        "outputId": "48488da4-d45a-4239-a9a2-3843eccd0c67"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN"
      ],
      "metadata": {
        "id": "cwLIDMLDa4yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Tạo model:\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "scores = cross_val_score(knn, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2nbrruHa1zD",
        "outputId": "b4202305-5692-4cf9-fccc-3b076d5999e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron"
      ],
      "metadata": {
        "id": "ZjNoMWHcbraX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.linear_model import Perceptron\n",
        "# Tạo model:\n",
        "pct = Perceptron()\n",
        "\n",
        "scores = cross_val_score(pct, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5-LpcVNbqpl",
        "outputId": "07f5fd04-f3bb-4e1b-de7d-4679eda5206e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "AAv3l1jyb0hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Tạo model:\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "scores = cross_val_score(rf, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVfchw2ib0Gx",
        "outputId": "14e95a34-c11e-497b-bb77-d76d93332b77"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adaboost"
      ],
      "metadata": {
        "id": "nbJyDp-ywpXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = RandomForestClassifier()\n",
        "scores = cross_val_score(ada, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOG_lHrzwrdr",
        "outputId": "76b48de4-aa15-4a29-fe13-7638d794d68c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Boost"
      ],
      "metadata": {
        "id": "6hdk3DGnw6Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "Gradboot = GradientBoostingClassifier(n_estimators=50)\n",
        "\n",
        "scores = cross_val_score(Gradboot, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4d7pex1w9I1",
        "outputId": "cef79d51-b827-42da-b28a-1be97a38396c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "sM0shFyodEns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Tạo model:\n",
        "nb = GaussianNB()\n",
        "\n",
        "scores = cross_val_score(nb, xtrain, ytrain, scoring='accuracy' ,cv=10).mean()\n",
        "\n",
        "print(\"The accuracy is %s\" % round(scores,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV3M5UAQc1cv",
        "outputId": "b4aa6e3d-70e5-4eb9-ed68-6eaf967a6a87"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thử trên test data\n"
      ],
      "metadata": {
        "id": "jYirbs8S0LHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boost**"
      ],
      "metadata": {
        "id": "NZUtijqsBQFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "gra = GradientBoostingClassifier(n_estimators=50)\n",
        "\n",
        "gra = gra.fit(xtrain, ytrain)\n",
        "\n",
        "predicted = gra.predict(xtest)\n",
        "\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp6jx6l6BTIb",
        "outputId": "f99d4e8e-dd9c-4245-e128-4894627c1ee8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adaboost**"
      ],
      "metadata": {
        "id": "6uuH6lZRBA9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import sklearn.metrics as metrics\n",
        "# Initiating the model:\n",
        "ada = AdaBoostClassifier(n_estimators=18)\n",
        "\n",
        "ada = ada.fit(xtrain, ytrain)\n",
        "\n",
        "predicted = ada.predict(xtest)\n",
        "\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCGSWe88Ap7q",
        "outputId": "0b34ab61-51e1-4821-bb44-190c6c0a34e7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FOREST**"
      ],
      "metadata": {
        "id": "nWp8EnLGgp04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn.metrics as metrics\n",
        "# Initiating the model:\n",
        "rf = RandomForestClassifier(n_estimators=18)\n",
        "\n",
        "rf = rf.fit(xtrain, ytrain)\n",
        "\n",
        "predicted = rf.predict(xtest)\n",
        "\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4ZsDlY70NyF",
        "outputId": "d20af30f-d3d5-4d8b-a4a4-442db6b288bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "tCAEriGxgukf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initiating the model:\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb = nb.fit(xtrain, ytrain)\n",
        "\n",
        "predicted = nb.predict(xtest)\n",
        "\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3vP2WsN0UZM",
        "outputId": "4af9064c-ca7a-4f31-be31-bc883c171f26"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perceptron**"
      ],
      "metadata": {
        "id": "eFcRP2rsg0GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.linear_model import Perceptron\n",
        "# Tạo model:\n",
        "pct = Perceptron()\n",
        "pct = pct.fit(xtrain, ytrain)\n",
        "predicted = pct.predict(xtest)\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Jqew3KfYVy",
        "outputId": "d111b3c9-98ac-46e5-a4f7-089157a78363"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**kNN**"
      ],
      "metadata": {
        "id": "LhPrUde_g3D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Tạo model:\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "knn = knn.fit(xtrain, ytrain)\n",
        "predicted = knn.predict(xtest)\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drTZu76MgEmh",
        "outputId": "c448d86a-0f89-4326-8158-97a86141c526"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LR**"
      ],
      "metadata": {
        "id": "-rRs5Ks3g475"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các model sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Tạo model:\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr = lr.fit(xtrain, ytrain)\n",
        "predicted = lr.predict(xtest)\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEzAHnTFgMW7",
        "outputId": "34636449-0f3d-4147-9c46-815ce15fe53b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "PO1_H5L6g6Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svm = svm.SVC()\n",
        "svm = svm.fit(xtrain, ytrain)\n",
        "predicted = svm.predict(xtest)\n",
        "acc_test = metrics.accuracy_score(ytest, predicted)\n",
        "\n",
        "print ('The accuracy on test data is %s' % (round(acc_test,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAPxGGyugacn",
        "outputId": "711b217e-f0dd-4b10-c509-07587db9ba25"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is 0.988\n"
          ]
        }
      ]
    }
  ]
}